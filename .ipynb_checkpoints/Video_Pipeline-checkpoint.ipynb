{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emotional-marshall",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding: Video Processing Pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-pharmacology",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "occasional-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-liechtenstein",
   "metadata": {},
   "source": [
    "## Class Definitions \n",
    "\n",
    "### Line( ), Lane( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broadband-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a class to receive the characteristics of each line detection\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        # x values of the previous high-confidence fit of the line\n",
    "        self.previousx = None\n",
    "        \n",
    "        #polynomial coefficients for the previous fit\n",
    "        self.previous_fit = None\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None   \n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        \n",
    "        #distance in meters of vehicle center from the line\n",
    "        #self.line_base_pos = None    ## Unused for sanity check, for offset we defined new variable\n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        #self.diffs = np.array([0,0,0], dtype='float')  ## can be used for sanity check\n",
    "        \n",
    "        \n",
    "        #x values for detected line pixels \n",
    "        #self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        #self.ally = None \n",
    "        ## can be used to fit a line (better, since averaging is linear - but fit is quadratic)\n",
    "    \n",
    "# Defined a class to receive the characteristics of each lane detection    \n",
    "    \n",
    "class Lane:\n",
    "    def __init__(self):\n",
    "        self.detected = False\n",
    "        self.sanity = False\n",
    "        self.offset = 0\n",
    "        self.radius_of_curvature = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-oxide",
   "metadata": {},
   "source": [
    "## Various Function Definitions for Pipeline\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-limitation",
   "metadata": {},
   "source": [
    "### Correcting for Image Distortion: \n",
    "\n",
    "Camera Matrix and Distortion co-efficients have been derived from a set of test chess-board images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "premium-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here image input is a colour one. Check if gray required (modify shape argument)\n",
    "\n",
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-decade",
   "metadata": {},
   "source": [
    "### Colour and Gradient Thresholding:\n",
    "\n",
    "Functions defined for sobel_x, sobel_y, sobel_xy and directional gradients\n",
    "\n",
    "As for Colour spaces, Hue and Saturation thresholds (HLS Space) and Red threshold (RGB Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "furnished-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Calculate directional gradient and apply threshold\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    " \n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude and apply threshold\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return dir_binary\n",
    "\n",
    "def sat_thresh(img,s_thresh=(90, 255)):\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    return s_binary\n",
    "\n",
    "def hue_thresh(img,h_thresh=(15, 100)):\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel >= h_thresh[0]) & (h_channel <= h_thresh[1])] = 1\n",
    "    \n",
    "    return h_binary\n",
    "\n",
    "def red_thresh(img,r_thresh=(200, 255)):\n",
    "\n",
    "    r_channel = img[:,:,0]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel >= r_thresh[0]) & (r_channel <= r_thresh[1])] = 1\n",
    "    \n",
    "    return r_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-lover",
   "metadata": {},
   "source": [
    "### Combining different thresholding functions\n",
    "\n",
    "In order to optimize the output binary image, a combination of the various functions defined above is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "willing-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_combined(undist):\n",
    "    \n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    \n",
    "    ## higher value, means additional pixels to left and right over which gradient is taken\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "\n",
    "    ## Gradient_thresholding\n",
    "\n",
    "    gradx = abs_sobel_thresh(undist, orient='x', sobel_kernel=ksize, thresh=(20, 100))  ##(10,150)\n",
    "    grady = abs_sobel_thresh(undist, orient='y', sobel_kernel=ksize, thresh=(20, 100))  ##(10,150)\n",
    "    mag_binary = mag_thresh(undist, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(undist, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "    ## Colour_thresholding\n",
    "    s_binary= sat_thresh(undist, s_thresh=(170,255))  ##changed from (90,255)\n",
    "    r_binary= red_thresh(undist, r_thresh=(230,255))\n",
    "    h_binary= hue_thresh(undist, h_thresh=(15,100))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1)) | ((s_binary==1) & (h_binary==1)) | r_binary==1] = 1\n",
    "    \n",
    "    # first two conditions identify crucial curve information\n",
    "    # S & H identify coloured lines and work well despite of shadows and change in lighting\n",
    "    # R is the best to identify white lines\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-curtis",
   "metadata": {},
   "source": [
    "### Perspective Transform\n",
    "\n",
    "Transform matrix M is derived from a test image where shape identification was simple\n",
    "\n",
    "Vehicle View -> Birds-Eye View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "little-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persp_transform(img,M,img_size):\n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-validity",
   "metadata": {},
   "source": [
    "### Some Additional Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loving-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_x_value (fit, y_eval):\n",
    "    \n",
    "    x_value = fit[0]*(y_eval**2) + fit[1]*y_eval + fit[2]\n",
    "    \n",
    "    return x_value\n",
    "\n",
    "def pixel2metre (left_fit_p, right_fit_p):\n",
    "    \n",
    "    # Converts polynomial co-efficients from pixel to meter units\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    my = 30/720 # meters per pixel in y dimension\n",
    "    mx = 3.7/680 # meters per pixel in x dimension (680 for us as offset was 300)\n",
    "    \n",
    "    left_fit_m = np.zeros_like(left_fit_p)  #zeroes_like[left_fit_p] ??\n",
    "    right_fit_m = np.zeros_like(right_fit_p)\n",
    "    \n",
    "    left_fit_m[0] = left_fit_p[0]* (mx / (my ** 2)) \n",
    "    left_fit_m[1] = left_fit_p[1]* (mx/my)\n",
    "    left_fit_m[2] = left_fit_p[2]* mx\n",
    "    \n",
    "    right_fit_m[0] = right_fit_p[0]* (mx / (my ** 2)) \n",
    "    right_fit_m[1] = right_fit_p[1]* (mx/my)\n",
    "    right_fit_m[2] = right_fit_p[2]* mx\n",
    "    \n",
    "    return left_fit_m, right_fit_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-atlantic",
   "metadata": {},
   "source": [
    "### Fitting Curves: Finding Lane lines\n",
    "\n",
    "#### Method 1: Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "similar-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    #out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "\n",
    "    \n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    \n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "        \n",
    "    #####AGAIN here error shouldnt be caused if we're using smoothing!!!!    \n",
    "\n",
    "    return left_fitx, right_fitx, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-canadian",
   "metadata": {},
   "source": [
    "#### Method 2: Search Around Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "chinese-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    \n",
    "    #try:\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    \n",
    "    #try:\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    #except:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "     #   print('The function failed to fit a line!')\n",
    "      #  left_fitx = 1*ploty**2 + 1*ploty\n",
    "       # right_fitx = 1*ploty**2 + 1*ploty\n",
    "    \n",
    "    return left_fitx, right_fitx, left_fit, right_fit\n",
    "\n",
    "def search_around_poly(binary_warped, left_fit, right_fit):\n",
    "    \n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, left_fit, right_fit = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "\n",
    "    return left_fitx, right_fitx, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-portuguese",
   "metadata": {},
   "source": [
    "### Radius of curvature and Vehicle offset \n",
    "\n",
    "Calculates the Radius of Curvature of the two lane lines and positional offset of vehicle center from lane center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "least-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(img_size, left_fit_m, right_fit_m):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    \n",
    "    ploty = np.linspace(0, img_size[1]-1, img_size[1])\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    my = 30/720 # meters per pixel in y dimension\n",
    "    mx = 3.7/680 # meters per pixel in x dimension (680 for us as offset was 300)\n",
    "    \n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image \n",
    "    # i.e position where the car is atm\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_lane = find_x_value(left_fit_m, y_eval*my) \n",
    "    right_lane = find_x_value(right_fit_m, y_eval*my)\n",
    "    \n",
    "    lane_center = (left_lane + right_lane)/2\n",
    "    frame_center = mx*640\n",
    "    offset = lane_center - frame_center\n",
    "    \n",
    "    # Implement the calculation of R_curve (radius of curvature) \n",
    "    left_curverad = int(((1 + (2*left_fit_m[0]*y_eval*my + left_fit_m[1])**2)**1.5) / np.absolute(2*left_fit_m[0]))\n",
    "    right_curverad = int(((1 + (2*right_fit_m[0]*y_eval*my + right_fit_m[1])**2)**1.5) / np.absolute(2*right_fit_m[0]))\n",
    "    \n",
    "    return left_curverad, right_curverad, offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-bankruptcy",
   "metadata": {},
   "source": [
    "### Smoothing:\n",
    "\n",
    "Adds the curve of current frame to list of previous frame curves and finds a weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "whole-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_average(left_fitx, left_lane, right_fitx, right_lane, img_size):\n",
    "    \n",
    "    ploty = np.linspace(0, img_size[1]-1, img_size[1])\n",
    "    \n",
    "    \n",
    "    ## for left line \n",
    "    \n",
    "    \n",
    "    left_lane.recent_xfitted.append(left_fitx)\n",
    "    \n",
    "    if (len(left_lane.recent_xfitted) > 5):    ## n = 5 is maximum number of curves to hold\n",
    "        \n",
    "        del left_lane.recent_xfitted[0]        ## deletes oldest curve\n",
    "        \n",
    "    weights = np.arange(1, len(left_lane.recent_xfitted) + 1)    ## List of weights = (1,2,3,4,5)\n",
    "        \n",
    "    left_lane.bestx = np.average(left_lane.recent_xfitted, axis = 0, weights = weights)\n",
    "        \n",
    "    left_lane.best_fit = np.polyfit(ploty, left_lane.bestx, 2)\n",
    "        \n",
    "        \n",
    "    ## for right line\n",
    "    \n",
    "    right_lane.recent_xfitted.append(right_fitx)\n",
    "    \n",
    "    if (len(right_lane.recent_xfitted) > 5):\n",
    "        \n",
    "        del right_lane.recent_xfitted[0]\n",
    "        \n",
    "    weights = np.arange(1, len(right_lane.recent_xfitted) + 1)\n",
    "        \n",
    "    right_lane.bestx = np.average(right_lane.recent_xfitted, axis = 0, weights = weights)\n",
    "        \n",
    "    right_lane.best_fit = np.polyfit(ploty, right_lane.bestx, 2)\n",
    "    \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-graphics",
   "metadata": {},
   "source": [
    "### Projecting Lanes:\n",
    "\n",
    "Projects the lane measurements back down onto the road!\n",
    "\n",
    "Displays curve information: Radius of Curvature and Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "alone-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lanes(undist, warped, left_fitx, right_fitx, curverad, img_size, offset):\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0])\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, img_size) \n",
    "    \n",
    "    # Creating Text and set font parameters\n",
    "    #TextL = \"Left  Curvature: \" + str(format(left_curverad)) + \" (m)\"\n",
    "    TextR = \"Radius of Curvature: \" + str(format(curverad))+ \" (m)\"\n",
    "    fontScale=1\n",
    "    thickness=2\n",
    "    fontFace =cv2.FONT_HERSHEY_SIMPLEX \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    # Using CV2 putText to write text into images\n",
    "    #cv2.putText(result, TextL, (110,110), fontFace, fontScale,(255,255,255), thickness,  lineType = cv2.LINE_AA)\n",
    "    cv2.putText(result, TextR, (110,60), fontFace, fontScale,(255,255,255), thickness,  lineType = cv2.LINE_AA)\n",
    "    \n",
    "    if offset < 0 :\n",
    "        TextC = \"Vehicle is \" + str(format(np.absolute(offset), \".2f\")) + \" (m) to the right of center\"\n",
    "    elif offset > 0 :    \n",
    "        TextC = \"Vehicle is \" + str(format(np.absolute(offset), \".2f\")) + \" (m) to the left of center\"\n",
    "    else:\n",
    "        TextC = \"Vehicle is at center\"\n",
    "    \n",
    "    cv2.putText(result, TextC, (110,110), fontFace, fontScale,(255,255,255), thickness,  lineType = cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-break",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "\n",
    "Performs multiple checks on curves fitted onto current frame in order to decide \n",
    "whether curve identification was effective\n",
    "\n",
    "1. Difference between left and right curvatures\n",
    "2. Lane width\n",
    "3. Parallel lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "expired-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(left_fit_m, right_fit_m, left_curverad, right_curverad):\n",
    "    \n",
    "    check = False\n",
    "    \n",
    "    straight_lanes = False\n",
    "    \n",
    "    if ((left_curverad > 1000) & (right_curverad > 1000)):\n",
    "        \n",
    "        straight_lanes = True\n",
    "    \n",
    "    curve_gap = np.absolute(left_curverad - right_curverad)\n",
    "    \n",
    "    lane_gap_base = np.absolute(find_x_value(left_fit_m, 30) - find_x_value(right_fit_m, 30))\n",
    "    \n",
    "    #lane_gap_mid = np.absolute(find_x_value(left_fit_m, 15) - find_x_value(right_fit_m, 15))\n",
    "    \n",
    "    lane_gap_top = np.absolute(find_x_value(left_fit_m, 0) - find_x_value(right_fit_m, 0))\n",
    "    \n",
    "    if (((curve_gap < 400) | (straight_lanes))  & (np.absolute(lane_gap_base - 3.7) < 0.5) & (np.absolute(lane_gap_top - 3.7) < 0.7)):\n",
    "        \n",
    "    ## can put 0.5 and 0.7 in terms of percentage (15% of lane width, 20% of lane width)\n",
    "    \n",
    "        check = True\n",
    "        \n",
    "    return check  \n",
    "        \n",
    "    # lane width check for reality check\n",
    "    # if the rad_curve are close enough and lane width is maintained, ~ lanes are parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-swaziland",
   "metadata": {},
   "source": [
    "## Choosing Pipeline:\n",
    "\n",
    "### 1. Sliding Windows Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "understanding-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_sliding(image):\n",
    "    \n",
    "    \n",
    "    img_size = (image.shape[1],image.shape[0])\n",
    "    \n",
    "    undist = cal_undistort(image,mtx,dist)\n",
    "    \n",
    "    combined = threshold_combined(undist)\n",
    "   \n",
    "    warped = persp_transform(combined, M, img_size)\n",
    "    \n",
    "    left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(warped)\n",
    "    \n",
    "    left_fit_m, right_fit_m = pixel2metre(left_fit, right_fit)\n",
    "\n",
    "    left_curverad, right_curverad, offset = measure_curvature_real(img_size, left_fit_m, right_fit_m)\n",
    "    \n",
    "    frame_check = sanity_check(left_fit_m, right_fit_m, left_curverad, right_curverad)\n",
    "    \n",
    "    global first_frame\n",
    "    \n",
    "    #print(frame_check)\n",
    "    \n",
    "    if (first_frame | frame_check):\n",
    "    \n",
    "        left_lane.bestx, right_lane.bestx = left_fitx, right_fitx\n",
    "        \n",
    "        left_lane.radius_of_curvature, right_lane.radius_of_curvature = left_curverad, right_curverad\n",
    "        \n",
    "        lane.radius_of_curvature = (left_lane.radius_of_curvature + right_lane.radius_of_curvature)/2\n",
    "        \n",
    "        lane.offset = offset\n",
    "        \n",
    "        left_lane.previous_fit, right_lane.previous_fit = left_fit, right_fit \n",
    "        \n",
    "        first_frame = False   \n",
    "       \n",
    "    result = draw_lanes(undist, warped, left_lane.bestx, right_lane.bestx, lane.radius_of_curvature, img_size, lane.offset)\n",
    "            \n",
    "    return result\n",
    "    \n",
    "    #result = draw_lanes(undist, warped, ploty, left_fitx, right_fitx, left_curverad, right_curverad, img_size, offset)\n",
    "    \n",
    "    #print(np.absolute(left_curverad - right_curverad))\n",
    "    \n",
    "    #lane_gap_base = np.absolute(find_x_value(left_fit, 30) - find_x_value(right_fit, 30))\n",
    "    \n",
    "    #lane_gap_mid = np.absolute(find_x_value(left_fit, 0) - find_x_value(right_fit, 0))\n",
    "    \n",
    "    #print(np.absolute(lane_gap_base - 3.7))\n",
    "    \n",
    "    #print(np.absolute(lane_gap_mid - 3.7))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-cleaning",
   "metadata": {},
   "source": [
    "### 2. Look-Ahead Filter with Sliding Windows as reset option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dangerous-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_skipping(image):\n",
    "    \n",
    "    \n",
    "    img_size = (image.shape[1],image.shape[0])\n",
    "    \n",
    "    undist = cal_undistort(image,mtx,dist)\n",
    "    \n",
    "    combined = threshold_combined(undist)\n",
    "   \n",
    "    warped = persp_transform(combined, M, img_size)\n",
    "    \n",
    "    global first_frame\n",
    "    \n",
    "    global frame_count\n",
    "    \n",
    "    if ( first_frame | (frame_count > 2)):\n",
    "    \n",
    "        left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(warped)\n",
    "        \n",
    "        #print('sliding')\n",
    "        \n",
    "        first_frame = False\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            left_fitx, right_fitx, left_fit, right_fit = search_around_poly(warped, left_lane.previous_fit, right_lane.previous_fit)\n",
    "        \n",
    "            #print('skipping')\n",
    "            \n",
    "        except TypeError: \n",
    "            \n",
    "            try: \n",
    "                \n",
    "                left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(warped)\n",
    "                \n",
    "                #print('sliding')\n",
    "            \n",
    "            except TypeError:\n",
    "                \n",
    "                pass\n",
    "                \n",
    "    left_fit_m, right_fit_m = pixel2metre(left_fit, right_fit)\n",
    "    \n",
    "    left_curverad, right_curverad, offset = measure_curvature_real(img_size, left_fit_m, right_fit_m)\n",
    "\n",
    "    frame_check = sanity_check(left_fit_m, right_fit_m, left_curverad, right_curverad)\n",
    "    \n",
    "    #print(frame_check)\n",
    "\n",
    "    if (frame_check):\n",
    "        \n",
    "        lane.detected = True\n",
    "\n",
    "        left_lane.bestx, right_lane.bestx = left_fitx, right_fitx\n",
    "\n",
    "        left_lane.radius_of_curvature, right_lane.radius_of_curvature = left_curverad, right_curverad\n",
    "        \n",
    "        lane.radius_of_curvature = (left_lane.radius_of_curvature + right_lane.radius_of_curvature)/2\n",
    "        \n",
    "        lane.offset = offset\n",
    "\n",
    "        left_lane.previous_fit, right_lane.previous_fit = left_fit, right_fit\n",
    "\n",
    "        frame_count = 0\n",
    "\n",
    "    else:\n",
    "\n",
    "        frame_count+=1\n",
    "    \n",
    "    \n",
    "    result = draw_lanes(undist, warped, left_lane.bestx, right_lane.bestx, lane.radius_of_curvature, img_size, lane.offset)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-cement",
   "metadata": {},
   "source": [
    "### 3. Complete Pipeline: Sanity Check, Tracking, Look-Ahead Filter, Reset and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "incomplete-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_smoothing(image):\n",
    "    \n",
    "    \n",
    "    img_size = (image.shape[1],image.shape[0])\n",
    "    \n",
    "    undist = cal_undistort(image,mtx,dist)\n",
    "    \n",
    "    combined = threshold_combined(undist)\n",
    "   \n",
    "    warped = persp_transform(combined, M, img_size)\n",
    "    \n",
    "    global frame_count\n",
    "    \n",
    "    if (lane.sanity == False | (frame_count > 2) | lane.detected == False):\n",
    "    \n",
    "        try:\n",
    "            \n",
    "            left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(warped)\n",
    "            \n",
    "            lane.detected = True\n",
    "            \n",
    "        except TypeError:\n",
    "            \n",
    "            lane.detected = False\n",
    "        \n",
    "        #print('sliding')\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            left_fitx, right_fitx, left_fit, right_fit = search_around_poly(warped, left_lane.previous_fit, right_lane.previous_fit)\n",
    "        \n",
    "            lane.detected = True\n",
    "            \n",
    "            #print('skipping')\n",
    "            \n",
    "        except TypeError: \n",
    "            \n",
    "            try: \n",
    "                \n",
    "                left_fitx, right_fitx, left_fit, right_fit = fit_polynomial(warped)\n",
    "                \n",
    "                lane.detected = True\n",
    "                \n",
    "                #print('sliding')\n",
    "            \n",
    "            except TypeError:\n",
    "                \n",
    "                lane.detected = False \n",
    "                \n",
    "    left_fit_m, right_fit_m = pixel2metre(left_fit, right_fit)\n",
    "    \n",
    "    left_curverad, right_curverad, offset = measure_curvature_real(img_size, left_fit_m, right_fit_m)\n",
    "    \n",
    "\n",
    "    frame_check = sanity_check(left_fit_m, right_fit_m, left_curverad, right_curverad)\n",
    "    \n",
    "    #print(frame_check)\n",
    "    \n",
    "\n",
    "    if (frame_check):\n",
    "        \n",
    "        lane.sanity = True\n",
    "        \n",
    "        left_lane.previousx, right_lane.previousx = left_fitx, right_fitx  # recording high-confidence result\n",
    "        \n",
    "        left_lane.previous_fit, right_lane.previous_fit = left_fit, right_fit # for use in search_poly (next iteration)\n",
    "        \n",
    "        append_average(left_fitx, left_lane, right_fitx, right_lane, img_size)\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        lane.sanity = False\n",
    "        \n",
    "        append_average(left_lane.previousx, left_lane, right_lane.previousx, right_lane, img_size)\n",
    "        \n",
    "        #instead of directly using previous best fit, increase the weight of previous frame fit and then average it\n",
    "        \n",
    "        frame_count+=1\n",
    "    \n",
    "    \n",
    "    left_fit_r, right_fit_r = pixel2metre(left_lane.best_fit, right_lane.best_fit)\n",
    "    \n",
    "    left_lane.radius_of_curvature, right_lane.radius_of_curvature, lane.offset = measure_curvature_real(img_size, left_fit_r, right_fit_r)\n",
    "\n",
    "    lane.radius_of_curvature = (left_lane.radius_of_curvature + right_lane.radius_of_curvature)/2\n",
    "\n",
    "    # Didn't need current_fit as it is available in left_fit/right_fit in the given iteration\n",
    "    # Hence, no need to store\n",
    "        \n",
    "    \n",
    "    result = draw_lanes(undist, warped, left_lane.bestx, right_lane.bestx, lane.radius_of_curvature, img_size, lane.offset)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-nowhere",
   "metadata": {},
   "source": [
    "### Initializations and reading in data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "static-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializations\n",
    "\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "lane = Lane()\n",
    "\n",
    "frame_count = 0\n",
    "frame_check = False\n",
    "first_frame = True\n",
    "\n",
    "# Read in the saved camera matrix and distortion co-efficients\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "persp_pickle = pickle.load( open( \"persp_pickle.p\", \"rb\" ) )\n",
    "M = persp_pickle[\"M\"]\n",
    "Minv = persp_pickle[\"Minv\"]\n",
    "\n",
    "### make sure persp_pickle is latest version from calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-august",
   "metadata": {},
   "source": [
    "## Running Pipeline on Video:\n",
    "\n",
    "Fill the selected pipeline option (process_image_sliding/process_image_skipping/process_image_smoothing) as the argument for clip1.fl_image( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "median-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/smoothing_pipeline.mp4.\n",
      "Moviepy - Writing video output_videos/smoothing_pipeline.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/smoothing_pipeline.mp4\n",
      "CPU times: user 3min 46s, sys: 48.6 s, total: 4min 34s\n",
      "Wall time: 3min 54s\n"
     ]
    }
   ],
   "source": [
    "write_output = 'output_videos/smoothing_pipeline.mp4'\n",
    "#write_output = 'output_videos/skipping_pipeline.mp4'\n",
    "#write_output = 'output_videos/sliding_pipeline.mp4'\n",
    "\n",
    "\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,5)\n",
    "\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image_smoothing) #NOTE: this function expects color images!!\n",
    "#white_clip = clip1.fl_image(process_image_skipping)\n",
    "#white_clip = clip1.fl_image(process_image_sliding)\n",
    "\n",
    "\n",
    "%time white_clip.write_videofile(write_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "native-manhattan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/smoothing_pipeline.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(write_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
